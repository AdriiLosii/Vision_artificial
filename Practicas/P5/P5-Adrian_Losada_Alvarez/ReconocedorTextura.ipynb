{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grado en Robótica - Visión Artificial\n",
    "## Práctica 5: Reconocedor de texturas y su evaluación\n",
    "### Autor: Adrián Losada Álvarez"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import mahotas\n",
    "import pandas as pd\n",
    "import Models_Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nota: Estas listas se utilizarán al final del documento para calcular las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Haralick_BL_predictions = []\n",
    "Haralick_BL_labels = []\n",
    "Haralick_Mahalanobis_predictions = []\n",
    "Haralick_Mahalanobis_labels = []\n",
    "LBP_BL_predictions = []\n",
    "LBP_BL_labels = []\n",
    "LBP_Mahalanobis_predictions = []\n",
    "LBP_Mahalanobis_labels = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de los dos algoritmos que reconocerán las texturas de las imágenes aportadas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer descriptor: **Haralick (GLCM)**\n",
    "Este descriptor funciona de la siguiente manera:\n",
    "1. **Construcción de la matriz de co-ocurrencia**: Representa la frecuencia con la que aparecen pares de valores de intensidad de gris a una distnacia y en una dirección dadas.\n",
    "\n",
    "2. **Normalización de la matriz**: La matriz se normaliza diviendo cada valor por el número total de pares de píxeles en la imagen, lo que da como resultado la probabilidad de que ocurra cada par de intensidades de gris.\n",
    "\n",
    "3. **Cálculo de características**: A partir de la matriz normalizada, se calculan varias características que describne la textura de la región de interés, como la enegía, la homogeneidad, el contraste, etc...\n",
    "\n",
    "4. **Análisis de características**: Estas características proporcionan información sobre la distribución de los niveles de girs en la imagne y se pueden utilizar para clasificar y comparar diferentes texturas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definimos los paths y los diccionarios para codificar y decodificar las clases de texturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los paths al directorio train y test\n",
    "train_path = './dataset/train/'\n",
    "test_path = './dataset/test/'\n",
    "\n",
    "# Diccionario para mapear clases de textura a números\n",
    "texture_mapping = {'canvas1': 0.0, 'cushion1': 1.0, 'linseeds1': 2.0, 'sand1': 3.0, 'seat2': 4.0, 'stone1': 5.0}\n",
    "\n",
    "# Diccionario inverso para mapear los números a las etiquetas de texto originales\n",
    "inverse_texture_mapping = {0.0: 'canvas1', 1.0: 'cushion1', 2.0: 'linseeds1', 3.0: 'sand1', 4.0: 'seat2', 5.0: 'stone1'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenemos las características de textura de las imágenes y las almacenamos en un archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Obteniendo las características de textura...\")\n",
    "# Inicializamos la matriz de datos y la lista de etiquetas\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Recorremos las imágenes de entrenamiento\n",
    "for folderName in os.listdir(train_path):\n",
    "    for imageName in os.listdir(train_path+folderName):\n",
    "        # Definir el path a la imagen actual\n",
    "        image_path = train_path+folderName+'/'+imageName\n",
    "\n",
    "        # Cargamos la imagen, la convertimos a gris y extraemos el nombre de la textura a partir del nombre del fichero\n",
    "        image = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        texture = image_path[image_path.rfind(\"/\") + 1:].split(\"_\")[0].split(\"-\")[0]\n",
    "\n",
    "        # Mapeamos la textura a su número asociado\n",
    "        label = texture_mapping.get(texture, -1)  # -1 si la textura no está mapeada\n",
    "\n",
    "        # Si la textura está mapeada, calculamos las características de Haralick\n",
    "        if label != -1:\n",
    "            # Obtenemos las características de Haralick de la imagen\n",
    "            features = mahotas.features.haralick(gray).mean(axis=0)\n",
    "\n",
    "            # Actualizamos los datos y las etiquetas\n",
    "            data.append(features)\n",
    "            labels.append(label)\n",
    "\n",
    "# Creamos un DataFrame para los datos y las etiquetas\n",
    "dataset = pd.DataFrame(data=np.array(data), columns=[f'feature_{i}' for i in range(len(data[0]))])\n",
    "dataset['texture'] = labels\n",
    "\n",
    "# Guardamos el DataFrame\n",
    "dataset.to_csv(\"./features/Haralick_features.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizamos el archivo CSV de las características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las columnas que siempre tienen valor '0.0' en el archivo CSV\n",
    "df = pd.read_csv('./features/Haralick_features.csv')\n",
    "\n",
    "# Encuentra las columnas\n",
    "columns_to_drop = []\n",
    "for column in df.columns:\n",
    "    if (df[column] == 0.0).all():\n",
    "        columns_to_drop.append(column)\n",
    "\n",
    "# Elimina las columnas encontradas\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Guarda el DataFrame resultante\n",
    "df.to_csv('./features/Haralick_features.csv', index=False)\n",
    "\n",
    "# Normalizamos el CSV\n",
    "Models_Metrics.normalizaCSV('./features/Haralick_features.csv', './features/Haralick_features_normalized.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos el modelo con el **clasificador Bayesiano lineal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el CSV con las características\n",
    "rawData = Models_Metrics.load_data('./features/Haralick_features_normalized.csv')\n",
    "data = Models_Metrics.Data(rawData, bias=False)\n",
    "\n",
    "print(\"[INFO] Entrenando el modelo...\")\n",
    "# Entrenamos el clasificador\n",
    "HaralickByLinearModel = Models_Metrics.ByLinear(data)\n",
    "HaralickByLinearModel.fix()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificamos las imágenes de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Clasificando...\")\n",
    "# Contar el número de clases y el número de imágenes por clase\n",
    "num_classes = len(os.listdir(test_path))\n",
    "num_images_per_class = len(os.listdir(os.path.join(test_path, os.listdir(test_path)[0])))\n",
    "\n",
    "# Obtenemos el valor máximo del CSV para normalizar posteriormente las características de las imágenes test\n",
    "valor_maximo = Models_Metrics.obtener_valor_maximo('./features/Haralick_features.csv')\n",
    "\n",
    "# Crear el subplot\n",
    "fig, axs = plt.subplots(num_classes, num_images_per_class, figsize=(20, 15))\n",
    "\n",
    "# Recorrer las imágenes de prueba y mostrarlas en el subplot\n",
    "for i, folderName in enumerate(sorted(os.listdir(test_path))):\n",
    "    class_images = []\n",
    "    for j, imageName in enumerate(sorted(os.listdir(os.path.join(test_path, folderName)))):\n",
    "        # Definir el path a la imagen actual\n",
    "        image_path = os.path.join(test_path, folderName, imageName)\n",
    "\n",
    "        # Cargamos la imagen, la convertimos a gris y extraemos el descriptor de Haralick de cada imagen de prueba\n",
    "        image = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        features = mahotas.features.haralick(gray).mean(axis=0)\n",
    "\n",
    "        # Elimina las mismas características que se eliminaron en el archivo CSV de la lista de features\n",
    "        new_features = []\n",
    "        for idx, feature in enumerate(features):\n",
    "            if ('feature_'+str(idx)) not in columns_to_drop:\n",
    "                new_features.append(feature)\n",
    "\n",
    "        # Normalizamos las características\n",
    "        norm_features = np.array(new_features)/valor_maximo\n",
    "\n",
    "        # Clasificamos la imagen de prueba\n",
    "        pred = HaralickByLinearModel.predict(norm_features.reshape(1, -1))\n",
    "        Haralick_BL_predictions.append(pred[0, 0])\n",
    "\n",
    "        # Visualización de los resultados\n",
    "        pred_text = \"Predicted: \" + inverse_texture_mapping[pred[0, 0]]  # Utilizando el diccionario inverso para pasar de número a texto de clase\n",
    "        text_size = cv2.getTextSize(pred_text, cv2.FONT_HERSHEY_SIMPLEX, 1.5, 3)[0] # Obtener el tamaño del texto\n",
    "        background_coords = ((40, 50 - text_size[1]), (40 + text_size[0], 50))  # Calcular la posición del rectángulo de fondo\n",
    "        cv2.rectangle(image, background_coords[0], background_coords[1], (0, 0, 0), -1) # Dibujar el rectángulo de fondo\n",
    "        cv2.putText(image, pred_text, (40, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)  # Agregar el texto con la predicción\n",
    "\n",
    "        # Añadir la imagen clasificada a la lista de imágenes de su clase\n",
    "        class_images.append(image)\n",
    "\n",
    "    # Mostrar las imágenes de la clase actual en una fila del subplot\n",
    "    for j in range(num_images_per_class):\n",
    "        axs[i, j].imshow(cv2.cvtColor(class_images[j], cv2.COLOR_BGR2RGB))\n",
    "        axs[i, j].set_title(\"Texture: \" + folderName)\n",
    "        Haralick_BL_labels.append(texture_mapping[folderName])\n",
    "        axs[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos el modelo con la **métrica de Mahalanobis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el CSV con las características\n",
    "rawData = Models_Metrics.load_data('./features/Haralick_features_normalized.csv')\n",
    "data = Models_Metrics.Data(rawData, bias=False)\n",
    "\n",
    "print(\"[INFO] Entrenando el modelo...\")\n",
    "# Entrenamos el clasificador\n",
    "HaralickMahalanobisModel = Models_Metrics.MahalanobisMetric(data)\n",
    "HaralickMahalanobisModel.fix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificamos las imágenes de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Clasificando...\")\n",
    "# Contar el número de clases y el número de imágenes por clase\n",
    "num_classes = len(os.listdir(test_path))\n",
    "num_images_per_class = len(os.listdir(os.path.join(test_path, os.listdir(test_path)[0])))\n",
    "\n",
    "# Obtenemos el valor máximo del CSV para normalizar posteriormente las características de las imágenes test\n",
    "valor_maximo = Models_Metrics.obtener_valor_maximo('./features/Haralick_features.csv')\n",
    "\n",
    "# Crear el subplot\n",
    "fig, axs = plt.subplots(num_classes, num_images_per_class, figsize=(20, 15))\n",
    "\n",
    "# Recorrer las imágenes de prueba y mostrarlas en el subplot\n",
    "for i, folderName in enumerate(sorted(os.listdir(test_path))):\n",
    "    class_images = []\n",
    "    for j, imageName in enumerate(sorted(os.listdir(os.path.join(test_path, folderName)))):\n",
    "        # Definir el path a la imagen actual\n",
    "        image_path = os.path.join(test_path, folderName, imageName)\n",
    "\n",
    "        # Cargamos la imagen, la convertimos a gris y extraemos el descriptor de Haralick de cada imagen de prueba\n",
    "        image = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        features = mahotas.features.haralick(gray).mean(axis=0)\n",
    "\n",
    "        # Elimina las mismas características que se eliminaron en el archivo CSV de la lista de features\n",
    "        new_features = []\n",
    "        for idx, feature in enumerate(features):\n",
    "            if ('feature_'+str(idx)) not in columns_to_drop:\n",
    "                new_features.append(feature)\n",
    "\n",
    "        # Normalizamos las características\n",
    "        norm_features = np.array(new_features)/valor_maximo\n",
    "\n",
    "        # Clasificamos la imagen de prueba\n",
    "        pred = HaralickMahalanobisModel.predict(norm_features.reshape(1, -1))\n",
    "        Haralick_Mahalanobis_predictions.append(pred[0])\n",
    "\n",
    "        # Visualización de los resultados\n",
    "        pred_text = \"Predicted: \" + inverse_texture_mapping[pred[0]]  # Utilizando el diccionario inverso para pasar de número a texto de clase\n",
    "        text_size = cv2.getTextSize(pred_text, cv2.FONT_HERSHEY_SIMPLEX, 1.5, 3)[0] # Obtener el tamaño del texto\n",
    "        background_coords = ((40, 50 - text_size[1]), (40 + text_size[0], 50))  # Calcular la posición del rectángulo de fondo\n",
    "        cv2.rectangle(image, background_coords[0], background_coords[1], (0, 0, 0), -1) # Dibujar el rectángulo de fondo\n",
    "        cv2.putText(image, pred_text, (40, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)  # Agregar el texto con la predicción\n",
    "\n",
    "        # Añadir la imagen clasificada a la lista de imágenes de su clase\n",
    "        class_images.append(image)\n",
    "\n",
    "    # Mostrar las imágenes de la clase actual en una fila del subplot\n",
    "    for j in range(num_images_per_class):\n",
    "        axs[i, j].imshow(cv2.cvtColor(class_images[j], cv2.COLOR_BGR2RGB))\n",
    "        axs[i, j].set_title(\"Texture: \" + folderName)\n",
    "        Haralick_Mahalanobis_labels.append(texture_mapping[folderName])\n",
    "        axs[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segundo descriptor: **Linear Binary Patterns (LBP)**\n",
    "Este descriptor funciona de la siguiente manera:\n",
    "1. **Definición de vecindarios**: Se define un vecindario alrededor de cada píxel de la imagen. Este vecindario puede ser un círculo, un cuadrado o cualquier forma definida por el usuario. Comúnmente, se utiliza un vecindario circular. Además, el tamaño de este puede variar.\n",
    "\n",
    "2. **Cálculo de los patrones binarios**: Para cada píxel de la imagen, se compara su valor de intensidad con los valores de intensidad de sus vecinos en el vecindario definido. Se asigna un bit (1 o 0) a cada vecino según si su intensidad es mayor o menor que la del píxel central respectivamente. Estos bits se concatenan para formar un número binario.\n",
    "\n",
    "3. **Histograma de patrones binarios**: Se construye un histograma contando la frecuencia de cada patrón binario en la imagen. Este histograma representa la distribución de los patrones locales en la imagen.\n",
    "\n",
    "4. **Características LBP**: A partir del histograma de patrones binarios, se pueden calcular diversas características para describir la textura de la imagen, como la media, la varianza, etc. También es común utilizar directamente el histograma como un descriptor de la textura.\n",
    "\n",
    "En este caso utilizaremos un radio de valor 1 y 8 puntos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definimos los paths y los diccionarios para codificar y decodificar las clases de texturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los paths al directorio train y test\n",
    "train_path = './dataset/train/'\n",
    "test_path = './dataset/test/'\n",
    "\n",
    "# Diccionario para mapear clases de textura a números\n",
    "texture_mapping = {'canvas1': 0, 'cushion1': 1, 'linseeds1': 2, 'sand1': 3, 'seat2': 4, 'stone1': 5}\n",
    "\n",
    "# Diccionario inverso para mapear los números a las etiquetas de texto originales\n",
    "inverse_texture_mapping = {0: 'canvas1', 1: 'cushion1', 2: 'linseeds1', 3: 'sand1', 4: 'seat2', 5: 'stone1'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtenemos las características de textura de las imágenes y las almacenamos en un archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Obteniendo las características de textura...\")\n",
    "# Inicializamos la matriz de datos y la lista de etiquetas\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Recorremos las imágenes de entrenamiento\n",
    "for folderName in os.listdir(train_path):\n",
    "    for imageName in os.listdir(train_path+folderName):\n",
    "        # Definir el path a la imagen actual\n",
    "        image_path = train_path+folderName+'/'+imageName\n",
    "\n",
    "        # Cargamos la imagen, la convertimos a gris y extraemos el nombre de la textura a partir del nombre del fichero\n",
    "        image = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        texture = image_path[image_path.rfind(\"/\") + 1:].split(\"_\")[0].split(\"-\")[0]\n",
    "\n",
    "        # Mapeamos la textura a su número asociado\n",
    "        label = texture_mapping.get(texture, -1)  # -1 si la textura no está mapeada\n",
    "\n",
    "        # Si la textura está mapeada, calculamos las características de Haralick\n",
    "        if label != -1:\n",
    "            # Extraemos las características de LBP con un radio de 1 y 8 puntos\n",
    "            features = mahotas.features.lbp(gray, 1, 8)\n",
    "\n",
    "            # Actualizamos los datos y las etiquetas\n",
    "            data.append(features)\n",
    "            labels.append(label)\n",
    "\n",
    "# Creamos un DataFrame para los datos y las etiquetas\n",
    "dataset = pd.DataFrame(data=np.array(data), columns=[f'feature_{i}' for i in range(len(data[0]))])\n",
    "dataset['texture'] = labels\n",
    "\n",
    "# Guardamos el DataFrame en un archivo CSV\n",
    "dataset.to_csv(\"./features/LBP_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizamos el archivo CSV de las características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las columnas que siempre tienen valor '0.0' en el archivo CSV\n",
    "df = pd.read_csv('./features/LBP_features.csv')\n",
    "\n",
    "# Encuentra las columnas\n",
    "columns_to_drop = []\n",
    "for column in df.columns:\n",
    "    if (df[column] == 0.0).all():\n",
    "        columns_to_drop.append(column)\n",
    "\n",
    "# Elimina las columnas encontradas\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Guarda el DataFrame resultante\n",
    "df.to_csv('./features/LBP_features.csv', index=False)\n",
    "\n",
    "# Normalizamos el CSV\n",
    "Models_Metrics.normalizaCSV('./features/LBP_features.csv', './features/LBP_features_normalized.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamos el modelo con el **clasificador Bayesiano lineal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el CSV con las características\n",
    "rawData = Models_Metrics.load_data('./features/LBP_features_normalized.csv')\n",
    "data = Models_Metrics.Data(rawData, bias=False)\n",
    "\n",
    "print(\"[INFO] Entrenando el modelo...\")\n",
    "# Entrenamos el clasificador\n",
    "LBPByLinearModel = Models_Metrics.ByLinear(data)\n",
    "LBPByLinearModel.fix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clasificamos las imágenes de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Clasificando...\")\n",
    "# Contar el número de clases y el número de imágenes por clase\n",
    "num_classes = len(os.listdir(test_path))\n",
    "num_images_per_class = len(os.listdir(os.path.join(test_path, os.listdir(test_path)[0])))\n",
    "\n",
    "# Obtenemos el valor máximo del CSV para normalizar posteriormente las características de las imágenes test\n",
    "valor_maximo = Models_Metrics.obtener_valor_maximo('./features/LBP_features.csv')\n",
    "\n",
    "# Crear el subplot\n",
    "fig, axs = plt.subplots(num_classes, num_images_per_class, figsize=(20, 15))\n",
    "\n",
    "# Recorrer las imágenes de prueba y mostrarlas en el subplot\n",
    "for i, folderName in enumerate(sorted(os.listdir(test_path))):\n",
    "    class_images = []\n",
    "    for j, imageName in enumerate(sorted(os.listdir(os.path.join(test_path, folderName)))):\n",
    "        # Definir el path a la imagen actual\n",
    "        image_path = os.path.join(test_path, folderName, imageName)\n",
    "\n",
    "        # Cargamos la imagen, la convertimos a gris y extraemos las características con el descriptor LBP de cada imagen de prueba\n",
    "        image = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        features = mahotas.features.lbp(gray, 1, 8)\n",
    "\n",
    "        # Elimina las mismas características que se eliminaron en el archivo CSV de la lista de features\n",
    "        new_features = []\n",
    "        for idx, feature in enumerate(features):\n",
    "            if ('feature_'+str(idx)) not in columns_to_drop:\n",
    "                new_features.append(feature)\n",
    "\n",
    "        # Normalizamos las características\n",
    "        norm_features = np.array(new_features)/valor_maximo\n",
    "\n",
    "        # Clasificamos la imagen de prueba\n",
    "        pred = LBPByLinearModel.predict(norm_features.reshape(1, -1))\n",
    "        LBP_BL_predictions.append(pred[0, 0])\n",
    "\n",
    "        # Visualización de los resultados\n",
    "        pred_text = \"Predicted: \" + inverse_texture_mapping[pred[0, 0]]  # Utilizando el diccionario inverso para pasar de número a texto de clase\n",
    "        text_size = cv2.getTextSize(pred_text, cv2.FONT_HERSHEY_SIMPLEX, 1.5, 3)[0] # Obtener el tamaño del texto\n",
    "        background_coords = ((40, 50 - text_size[1]), (40 + text_size[0], 50))  # Calcular la posición del rectángulo de fondo\n",
    "        cv2.rectangle(image, background_coords[0], background_coords[1], (0, 0, 0), -1) # Dibujar el rectángulo de fondo\n",
    "        cv2.putText(image, pred_text, (40, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)  # Agregar el texto con la predicción\n",
    "\n",
    "        # Añadir la imagen clasificada a la lista de imágenes de su clase\n",
    "        class_images.append(image)\n",
    "\n",
    "    # Mostrar las imágenes de la clase actual en una fila del subplot\n",
    "    for j in range(num_images_per_class):\n",
    "        axs[i, j].imshow(cv2.cvtColor(class_images[j], cv2.COLOR_BGR2RGB))\n",
    "        axs[i, j].set_title(\"Correct class: \" + folderName)\n",
    "        LBP_BL_labels.append(texture_mapping[folderName])\n",
    "        axs[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos el modelo con la **métrica de Mahalanobis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el CSV con las características\n",
    "rawData = Models_Metrics.load_data('./features/LBP_features_normalized.csv')\n",
    "data = Models_Metrics.Data(rawData, bias=False)\n",
    "\n",
    "print(\"[INFO] Entrenando el modelo...\")\n",
    "# Entrenamos el clasificador\n",
    "LBPMahalanobisModel = Models_Metrics.MahalanobisMetric(data, alpha=1e-6)\n",
    "LBPMahalanobisModel.fix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clasificamos las imágenes de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Clasificando...\")\n",
    "# Contar el número de clases y el número de imágenes por clase\n",
    "num_classes = len(os.listdir(test_path))\n",
    "num_images_per_class = len(os.listdir(os.path.join(test_path, os.listdir(test_path)[0])))\n",
    "\n",
    "# Obtenemos el valor máximo del CSV para normalizar posteriormente las características de las imágenes test\n",
    "valor_maximo = Models_Metrics.obtener_valor_maximo('./features/LBP_features.csv')\n",
    "\n",
    "# Crear el subplot\n",
    "fig, axs = plt.subplots(num_classes, num_images_per_class, figsize=(20, 15))\n",
    "\n",
    "# Recorrer las imágenes de prueba y mostrarlas en el subplot\n",
    "for i, folderName in enumerate(sorted(os.listdir(test_path))):\n",
    "    class_images = []\n",
    "    for j, imageName in enumerate(sorted(os.listdir(os.path.join(test_path, folderName)))):\n",
    "        # Definir el path a la imagen actual\n",
    "        image_path = os.path.join(test_path, folderName, imageName)\n",
    "\n",
    "        # Cargamos la imagen, la convertimos a gris y extraemos las características con el descriptor LBP de cada imagen de prueba\n",
    "        image = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        features = mahotas.features.lbp(gray, 1, 8)\n",
    "\n",
    "        # Elimina las mismas características que se eliminaron en el archivo CSV de la lista de features\n",
    "        new_features = []\n",
    "        for idx, feature in enumerate(features):\n",
    "            if ('feature_'+str(idx)) not in columns_to_drop:\n",
    "                new_features.append(feature)\n",
    "\n",
    "        # Normalizamos las características\n",
    "        norm_features = np.array(new_features)/valor_maximo\n",
    "\n",
    "        # Clasificamos la imagen de prueba\n",
    "        pred = LBPMahalanobisModel.predict(norm_features.reshape(1, -1))\n",
    "        LBP_Mahalanobis_predictions.append(pred[0])\n",
    "\n",
    "        # Visualización de los resultados\n",
    "        pred_text = \"Predicted: \" + inverse_texture_mapping[pred[0]]  # Utilizando el diccionario inverso para pasar de número a texto de clase\n",
    "        text_size = cv2.getTextSize(pred_text, cv2.FONT_HERSHEY_SIMPLEX, 1.5, 3)[0] # Obtener el tamaño del texto\n",
    "        background_coords = ((40, 50 - text_size[1]), (40 + text_size[0], 50))  # Calcular la posición del rectángulo de fondo\n",
    "        cv2.rectangle(image, background_coords[0], background_coords[1], (0, 0, 0), -1) # Dibujar el rectángulo de fondo\n",
    "        cv2.putText(image, pred_text, (40, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)  # Agregar el texto con la predicción\n",
    "\n",
    "        # Añadir la imagen clasificada a la lista de imágenes de su clase\n",
    "        class_images.append(image)\n",
    "\n",
    "    # Mostrar las imágenes de la clase actual en una fila del subplot\n",
    "    for j in range(num_images_per_class):\n",
    "        axs[i, j].imshow(cv2.cvtColor(class_images[j], cv2.COLOR_BGR2RGB))\n",
    "        axs[i, j].set_title(\"Texture: \" + folderName)\n",
    "        LBP_Mahalanobis_labels.append(texture_mapping[folderName])\n",
    "        axs[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medidas de rendimiento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Obtención de métricas:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo: **Haralick**\n",
    "#### Clasificador: **Bayesiano Lineal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Haralick_BL_accuracy = accuracy_score(np.array(Haralick_BL_labels), np.array(Haralick_BL_predictions))\n",
    "Haralick_BL_precision = precision_score(np.array(Haralick_BL_labels), np.array(Haralick_BL_predictions), average='micro')\n",
    "Haralick_BL_recall = recall_score(np.array(Haralick_BL_labels), np.array(Haralick_BL_predictions), average='micro')\n",
    "Haralick_BL_f1_score = f1_score(np.array(Haralick_BL_labels), np.array(Haralick_BL_predictions), average='micro')\n",
    "Haralick_BL_confusion_matrix = confusion_matrix(np.array(Haralick_BL_labels), np.array(Haralick_BL_predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelo: **Haralick**\n",
    "##### Clasificador: **Mahalanobis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Haralick_Mahalanobis_accuracy = accuracy_score(np.array(Haralick_Mahalanobis_labels), np.array(Haralick_Mahalanobis_predictions))\n",
    "Haralick_Mahalanobis_precision = precision_score(np.array(Haralick_Mahalanobis_labels), np.array(Haralick_Mahalanobis_predictions), average='micro')\n",
    "Haralick_Mahalanobis_recall = recall_score(np.array(Haralick_Mahalanobis_labels), np.array(Haralick_Mahalanobis_predictions), average='micro')\n",
    "Haralick_Mahalanobis_f1_score = f1_score(np.array(Haralick_Mahalanobis_labels), np.array(Haralick_Mahalanobis_predictions), average='micro')\n",
    "Haralick_Mahalanobis_confusion_matrix = confusion_matrix(np.array(Haralick_Mahalanobis_labels), np.array(Haralick_Mahalanobis_predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelo: **LBP**\n",
    "##### Clasificador: **Bayesiano Lineal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LBP_BL_accuracy = accuracy_score(np.array(LBP_BL_labels), np.array(LBP_BL_predictions))\n",
    "LBP_BL_precision = precision_score(np.array(LBP_BL_labels), np.array(LBP_BL_predictions), average='micro')\n",
    "LBP_BL_recall = recall_score(np.array(LBP_BL_labels), np.array(LBP_BL_predictions), average='micro')\n",
    "LBP_BL_f1_score = f1_score(np.array(LBP_BL_labels), np.array(LBP_BL_predictions), average='micro')\n",
    "LBP_BL_confusion_matrix = confusion_matrix(np.array(LBP_BL_labels), np.array(LBP_BL_predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelo: **LBP**\n",
    "##### Clasificador: **Mahalanobis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LBP_Mahalanobis_accuracy = accuracy_score(np.array(LBP_Mahalanobis_labels), np.array(LBP_Mahalanobis_predictions))\n",
    "LBP_Mahalanobis_precision = precision_score(np.array(LBP_Mahalanobis_labels), np.array(LBP_Mahalanobis_predictions), average='micro')\n",
    "LBP_Mahalanobis_recall = recall_score(np.array(LBP_Mahalanobis_labels), np.array(LBP_Mahalanobis_predictions), average='micro')\n",
    "LBP_Mahalanobis_f1_score = f1_score(np.array(LBP_Mahalanobis_labels), np.array(LBP_Mahalanobis_predictions), average='micro')\n",
    "LBP_Mahalanobis_confusion_matrix = confusion_matrix(np.array(LBP_Mahalanobis_labels), np.array(LBP_Mahalanobis_predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostramos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
    "models = ['Haralick+BayeLinear(13 características)', 'Haralick+Mahalanobis(13 características)', 'LBP+BayeLinear(35 características)', 'LBP+Mahalanobis(35 características)']\n",
    "score_lists = [\n",
    "    [Haralick_BL_accuracy, Haralick_Mahalanobis_accuracy, LBP_BL_accuracy, LBP_Mahalanobis_accuracy],\n",
    "    [Haralick_BL_precision, Haralick_Mahalanobis_precision, LBP_BL_precision, LBP_Mahalanobis_precision],\n",
    "    [Haralick_BL_recall, Haralick_Mahalanobis_recall, LBP_BL_recall, LBP_Mahalanobis_recall],\n",
    "    [Haralick_BL_f1_score, Haralick_Mahalanobis_f1_score, LBP_BL_f1_score, LBP_Mahalanobis_f1_score]\n",
    "]\n",
    "\n",
    "# Dataframe con las métricas\n",
    "data = {'Modelo': models}\n",
    "for metric, score_list in zip(metrics, score_lists):\n",
    "    sorted_scores = sorted(score_list, reverse=True)\n",
    "    data[metric] = score_list\n",
    "    data[f'{metric.rjust(2)} Rank'] = [sorted_scores.index(score) + 1 for score in score_list]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Mostramos el DataFrame\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrices de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la lista con las matrices de confusión y los nombres correspondientes\n",
    "list_CM = [Haralick_BL_confusion_matrix, Haralick_Mahalanobis_confusion_matrix, LBP_BL_confusion_matrix, LBP_Mahalanobis_confusion_matrix]\n",
    "names = ['Haralick - Bayesiano Lineal', 'Haralick - Métrica Mahalanobis', 'Linear Binary Patterns - Bayesiano Lineal', 'Linear Binary Patterns - Métrica Mahalanobis']\n",
    "\n",
    "# Visualización\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        # Crea el heatmap utilizando seaborn\n",
    "        sns.heatmap(list_CM[i*2 + j], annot=True, cmap='Blues', fmt='g', \n",
    "                    xticklabels=['canvas1', 'cushion1', 'linseeds1', 'sand1', 'seat2', 'stone1'], \n",
    "                    yticklabels=['canvas1', 'cushion1', 'linseeds1', 'sand1', 'seat2', 'stone1'], ax=axes[i, j])\n",
    "        \n",
    "        # Etiquetas y título\n",
    "        axes[i, j].set_xlabel('Predicción')\n",
    "        axes[i, j].set_ylabel('Etiqueta Verdadera')\n",
    "        axes[i, j].set_title(names[i*2 + j])\n",
    "\n",
    "# Mostramos el resultado\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis de los resultados\n",
    "Observando los resultados podemos comprobar que, para la base de datos aportada, los dos descriptores con el clasificador Bayesiano lineal son capaces de identificar sin problema las distintas texturas. Utilizando la métrica de Mahalanobis como clasificador vemos que el resultado sigue siendo muy bueno, sin embargo, en el caso del descriptor de Halarick podemos comprobar que si ha tenido algún fallo a la hora de predecir.\n",
    "\n",
    "Estas métricas tan elevadas se pueden deber a que la base de datos tiene una dimensión bastante pequeña, además de que todas las imágenes de texturas estaban a la misma escala y misma orientación. Estos factores facilitan el reconocimiento y diferenciación de las distintas texturas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VAA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53e3713d2492df86f3f230a9890fee7d1a4758cc3b2a50c4b61b1b972bfca11c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
